{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook discusses the nearest neighbor classification implementation.\n",
    "Outline:\n",
    "    Demonstrate working of a simple k-NN classifier in Scikit-learn\n",
    "    Load iris dataset\n",
    "    Perform k-NN using Scikit-learn on the iris dataset\n",
    "    Vary similarity measures to see performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample dataset - 4 samples, two classes (0 and 1)\n",
    "# Use 2-D data\n",
    "X = [[0], [1], [2], [3]] # 4x1-dimensional\n",
    "y = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have above are one dimensional points. Logically, a decision boundary should exist at x = 1.5. We will verify if it holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print (neigh.predict([[1.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (neigh.predict([[1.6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get probability\n",
    "print (neigh.predict_proba([[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Now let's train a k-NN on Iris dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the dataset - \n",
    "Iris is a flower. The flower can belong to one of three categories - Setosa, Versicolour, and Virginica. Think of it as\n",
    "being equivalent to red rose, white rose and pink rose. Given the flower's features such as length of width of petals, we need\n",
    "to classify the flower into its correct category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features for simplicity\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "# Split training data into testing and validation data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "best_k = 1\n",
    "for n in range(1,16,2): # Takes values 1, 3, 5, .., 15\n",
    "    # initialize the classifier with value of number of neighbors\n",
    "    clf = KNeighborsClassifier(n)\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    predictions = clf.predict(X_valid)\n",
    "    accuracy = np.sum(predictions == y_valid)/(len(y_valid))\n",
    "    print (\"Accuracy = \" + str(accuracy) + \" at k = \" + str(n))\n",
    "    if (accuracy > best_acc):\n",
    "        best_k = n\n",
    "        best_acc = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train,X_valid))\n",
    "y_train = np.concatenate((y_train,y_valid))\n",
    "\n",
    "clf = KNeighborsClassifier(best_k)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print ('accuracy = ' + str(np.sum(predictions == y_test)/(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "By default 'Minkowski' distance with power 2 is used. Let us modify the distance measure to Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter 'p' is the Power parameter for the Minkowski metric.\n",
    "clf = KNeighborsClassifier(best_k, p=1) # p = 1 corresponds to Manhattan distance\n",
    "# p = 2 gives Euclidean distance (default is p = 2 and hence, Euclidean distance)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = np.sum(predictions == y_test)/(len(y_test))\n",
    "print (\"Accuracy = \" + str(accuracy) + \" at k = 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use DistanceMetric object \n",
    "See more at http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "n_neighbors = best_k\n",
    "\n",
    "# Uniform weights - All points in each neighborhood are weighted equally.\n",
    "# distance : weight points by the inverse of their distance. \n",
    "# --> In this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
